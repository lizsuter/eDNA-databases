# Build Primer-Specific Databases Using rCRUX
Based on [Curd et al. 2023](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10312559/)  
[rCRUX repo](https://github.com/CalCOFI/rCRUX?tab=readme-ov-file)

## July 2024
### Install/ Update NCBI's BLAST+ Toolkit

Downloaded the .dmg installer (v2.10.1 is last update that is confirmed compatible with rCRUX) from https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/ and followed instructions [here](https://www.ncbi.nlm.nih.gov/books/NBK569861/) on installation


### Download Blast-formatted database
Download of entire NCBI nt database is in chunks. Latest is nt.146, updated 6/10/2024 (see [here](https://ftp.ncbi.nlm.nih.gov/blast/db/)). Donwload all (takes many hours).

(run in terminal)

```{bash}
mkdir NCBI_blast_nt
cd NCBI_blast_nt
wget "ftp://ftp.ncbi.nlm.nih.gov/blast/db/nt.???.tar.gz*" -c
time for file in *.tar.gz; do tar -zxvf $file; done
cd ..

# had some errors unzipping due to space constraints. After moving files around, I want to retry unzipping files 137-185

for i in {121..185}; do
  time for file in nt.$i.tar.gz; do tar -zxvf $file; done
done
```
You need to download ALL nt files: https://bioinformatics.stackexchange.com/questions/17918/do-i-have-to-download-all-nt-xx-files-to-perform-a-search-in-blastn-2-12-0
The ???in file name allows you to get all 146 nt updates (as of Jul 2024)
As of Oct 2024: 185 files in nt


#### Check blast+ install and database download
```{bash}
blastdbcmd -db 'NCBI_blast_nt/nt' -dbtype nucl -entry MN937193.1 -range 499-633
```
* Note the above only works in my `REVAMPenv` (run `conda activate REVAMPenv`) which has correct version of blast tools. See Elas02-notebook.md for more details.




### Install/ Update Taxonomizr Taxonomy
Was getting errors that I didn't have libcurl. Needed to update `curl`, which required new version of Apple Command Line Tools to be installed with: `xcode-select --install` and various updates to Homebrew. Then installed with Homebrew using `brew install curl`. YMMV

Install/ load [taxonomizr](https://github.com/sherrillmix/taxonomizr)
```{r}
# install.packages("taxonomizr")
library(taxonomizr)
```


Download tax assignments from NCBI and make SQLite database (this takes several hours) following instructions from [https://github.com/sherrillmix/taxonomizr](https://github.com/sherrillmix/taxonomizr). 

```{r}
#accession_taxa_sql_path <- "taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql"
#prepareDatabase(accession_taxa_sql_path, )

# the above was working in July but in Oct kept giving error so I had to do it manually according to docs

getAccession2taxid(baseUrl='https://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/', resume = TRUE)
read.names.sql('names.dmp','taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql', overwrite = TRUE)
read.nodes.sql('nodes.dmp','taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql', overwrite = TRUE)

read.accession2taxid(list.files('.','accession2taxid.gz$'),'taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql')

```

Update again in Jan 2025
```{r}
accession_taxa_sql_path <- "taxonomizr-acc-taxa-Jan2025/accessionTaxa.sql"
prepareDatabase(accession_taxa_sql_path)
```


### Install rCRUX

```{r}
# install.packages("devtools")
# devtools::install_github("CalCOFI/rCRUX", build_vignettes = TRUE)
library("rCRUX")
```



### rCRUX - Build Elas02 Database




### Get seeds
Use local option after downloading entire nt database. (If running remote, the NCBI taxID for [Elasmobranchii](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=7778) is 7778)

Primers are Elas02from [Taberlet et al. 2018](https://academic.oup.com/book/32663?login=true); Note: this is a book chapter but the full primers are also published in Table 1 in [Collins et al. 2019](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13276). Amplify a subregion of 12S rRNA that is 171 bp long.

Elas02-f, 5’-3’: GTTGGTHAATCTCGTGCCAGC
Elas02-r, 5’-3’: CATAGTAGGGTATCTAATCCTAGTTTG


```{r}
# dir.create("Taberlet-elas02-local-20240612")

forward_primer_seq = "GTTGGTHAATCTCGTGCCAGC"
reverse_primer_seq =  "CATAGTAGGGTATCTAATCCTAGTTTG"
output_directory_path <- "Taberlet-elas02-local-20240612/" # path to desired output directory
metabarcode_name <- "elas02" # desired name of metabarcode locus
accession_taxa_sql_path <- "taxonomizr-acc-taxa-Jun2024/accessionTaxa.sql" # path to taxonomizr sql database
blast_db_path <- "NCBI_blast_nt/nt"  # path to blast formatted database


get_seeds_local(forward_primer_seq,
                 reverse_primer_seq,
                 metabarcode_name,
                 output_directory_path,
                 accession_taxa_sql_path,
                 blast_db_path, mismatch = 3, max_to_blast = 3)

```


### Blast seeds

```{r}
seeds_output_path <- 'Taberlet-elas02-local-20240612/get_seeds_local/elas02_filtered_get_seeds_local_output_with_taxonomy.csv' # this is output from get_seeds_local or get_seeds_remote
blast_db_path <- "NCBI_blast_nt/nt"  # path to blast formatted database
accession_taxa_sql_path <- "taxonomizr-acc-taxa-Jun2024/accessionTaxa.sql" # path to taxonomizr sql database
output_directory_path <- 'Taberlet-elas02-local-20240612/' # path to desired output directory
metabarcode_name <- "elas02"  # desired name of metabarcode locus


blast_seeds(seeds_output_path,
            blast_db_path,
            accession_taxa_sql_path,
            output_directory_path,
            metabarcode_name)    
```


### Dereplicate database

```{r}
output_directory_path <- 'Taberlet-elas02-local-20240612/' # path to desired output directory
metabarcode_name <- "elas02"  # desired name of metabarcode locus
summary_path <- "Taberlet-elas02-local-20240612/blast_seeds_output/summary.csv" # path to the output from blast_seeds

derep_and_clean_db(output_directory_path, summary_path, metabarcode_name)
```

Checked `elas02_derep_and_clean_taxonomy.txt` for known expected taxa (eg. Mustelus canis, Squalus acanthias, Raja eglanteria, Bathytoshia centroura, Rhinoptera bonasus, Leucoraja erinacea, Leucoraja ocellata, Carcharias taurus, Isurus oxyrinchus, Amblyraja radiata, Myliobatis freminvillei, Gymnura altavela)- all exist (plus many more).

### Make into blast formatted db

[Documentation](https://www.ncbi.nlm.nih.gov/books/NBK569841/)
(Run interminal)

---
7/1/2024
Trying to make mapping file. I tried to a long time to grab the results from rCRUX in `derep_and_clean_db`, the taxid columns from `Sequences_with_single_taxonomic_path.csv` and `Sequences_with_multiple_taxonomic_paths.csv` . But the problem is that the pipeline puts multiple acc no's and taxids into on row if they are repeated sequences. I tried forvever but couldn't get `makeblastdb` to accept this format, no matter if I change the delimiter etc. (eg. using some tips from [here](https://bioinformatics.stackexchange.com/questions/18401/assign-multiple-taxids-to-a-sequence-when-constructing-a-local-blast-database))


Instead, try grabbing a list of acc no's from the fasta file and get taxID using taxonomizr (installed above)

First remove excess text from fasta file
```{bash}
cd Taberlet-elas02-local-20240612/derep_and_clean_db/
sed 's/_representative_of_[0-9]*_identical_accessions//g' elas02_derep_and_clean.fasta > elas02_derep_and_clean_2.fasta
cd ..
```
(Note different syntax for `sed` in [Mac OS vs other OS](https://www.cyberciti.biz/faq/how-to-use-sed-to-find-and-replace-text-in-files-in-linux-unix-shell/))


Get list of acc no's into new file
```{bash}
grep -e ">" elas02_derep_and_clean_2.fasta | awk 'sub(/^>/, "")' > AccNos.txt

```

Move into R
```{r}
accNos <-  read.table(file = "Taberlet-elas02-local-20240612/derep_and_clean_db/AccNos.txt", header=FALSE,stringsAsFactors=FALSE)

accessions<-sapply(strsplit(accNos[,1],'\\|'),'[',1)
head(accessions)
```

Find taxonomy for accession numbers (takes a few minutes)
```{r}
taxaId<-accessionToTaxa(accessions,"taxonomizr-acc-taxa-Jun2024/accessionTaxa.sql")
head(taxaId)
```


Concatenate with acc nos and export into txt file
```{r}
mapping_file <- data.frame(accessions, taxaId)
head(mapping_file)
```

```{r}
write.table(mapping_file, "Taberlet-elas02-local-20240612/mapping_file.txt", sep='\t', col.names = FALSE, row.names = FALSE, quote=FALSE)
```




Use blast+ to make blastdb and call it nt (because this is how it's called in REVAMP pipeline. Want to try not to modify `REVAMP.sh` as much as possible)

```{bash}
mkdir blastdb

makeblastdb -in derep_and_clean_db/elas02_derep_and_clean_2.fasta -dbtype nucl -parse_seqids -out blastdb/nt -blastdb_version 5 -taxid_map mapping_file.txt
```


And check that the database has taxIDs associated:
```{bash}
blastdbcmd -db blastdb/nt -entry all -outfmt "%T"
```
As long as this spits out numbers and not all zeroes, I think it worked.




## October 2024


### rCRUX - Build MiFish-U Database
Update local nt database

Check blast+ install and database download
```{bash}

cd /Volumes/easystore/eDNA/eDNA-databases/NCBI_blast_nt

conda activate REVAMPenv


## update local database
# update_blastdb.pl --decompress nt

# check
blastdbcmd -db 'nt' -dbtype nucl -entry MN937193.1 -range 499-633
blastn -version

```
blastn: 2.10.1+
 Package: blast 2.10.1, build May 12 2020 13:06:02


Primers are universal MiFISh primers from Miya et al. 2015. Amplify a subregion of 12S rRNA that is 163-185 bp long.

MiFISH-U-F, 5’-3’: GTCGGTAAAACTCGTGCCAGC 
MiFISH-U-R, 5’-3’: CATAGTGGGGTATCTAATCCCAGTTTG 


```{r}
# dir.create("MiFish-U-local-20241011")

forward_primer_seq = "GTCGGTAAAACTCGTGCCAGC"
reverse_primer_seq =  "CATAGTGGGGTATCTAATCCCAGTTTG"
output_directory_path <- "MiFish-U-local-20241011/" # path to desired output directory
metabarcode_name <- "MiFishU" # desired name of metabarcode locus
accession_taxa_sql_path <- "taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql" # path to taxonomizr sql database
blast_db_path <- "/Volumes/MyPassport/eDNA-backup/databases/NCBI_blast_nt/nt"  # path to blast formatted database


get_seeds_local(forward_primer_seq,
                 reverse_primer_seq,
                 metabarcode_name,
                 output_directory_path,
                 accession_taxa_sql_path,
                 blast_db_path, mismatch = 3, max_to_blast = 2)

```
Ran in Console instead of chunk bc of memory issues. Output:

```
[1] "output directory exists"
Output directory: MiFish-U-local-20241011//get_seeds_local

No previous primer blast files found. Starting pipeline from beginning.

Examining primers for degenerate bases.
  1 forward primer(s) will be blasted.
  1 reverse primer(s) will be blasted.

Reads will be blasted in subsets of up to 2 read(s). To change this, modify max_to_blast.                        

Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassport/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query MiFish-U-local-20241011//get_seeds_local/MiFishU_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1

Blasting complete.

Wrangling results.

Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Joining with `by = join_by(saccver)`
Attaching taxonomies.

Done.
# A tibble: 56,038 × 37
   qseqid.x      gi     accession mismatch_forward forward_start forward_stop staxids distinct_entries.x qseqid.y
   <chr>         <chr>  <chr>     <chr>                    <int>        <int> <chr>                <int> <chr>   
 1 forward_row_1 10483… 3JD5_A    2                          223          243 9913                     2 reverse…
 2 forward_row_1 81051… 5AJ3_A    2                          228          248 9823                     2 reverse…
 3 forward_row_1 22540… 7PNT_A    3                          224          244 10090                    2 reverse…
 4 forward_row_1 22540… 7PNV_A    3                          224          244 10090                    2 reverse…
 5 forward_row_1 25190… 8OIN_AA   2                          226          246 9823                     2 reverse…
 6 forward_row_1 25096… 8OIP_AA   2                          228          248 9823                     2 reverse…
 7 forward_row_1 18164… AB000667… 0                         2697         2715 8255                     2 reverse…
 8 forward_row_1 45869… AB018224… 1                          228          248 76798                    2 reverse…
 9 forward_row_1 45869… AB018225… 1                          228          248 83387                    2 reverse…
10 forward_row_1 45869… AB018226… 1                          229          247 83388                    2 reverse…
# ℹ 56,028 more rows
# ℹ 28 more variables: mismatch_reverse <chr>, reverse_start <int>, reverse_stop <int>,
#   distinct_entries.y <int>, product_length <dbl>, taxid <int>, species <chr>, superkingdom <chr>,
#   kingdom <chr>, phylum <chr>, subphylum <chr>, superclass <chr>, class <chr>, subclass <chr>, order <chr>,
#   family <chr>, subfamily <chr>, genus <chr>, infraorder <chr>, subcohort <chr>, superorder <chr>,
#   superfamily <chr>, tribe <chr>, subspecies <chr>, subgenus <chr>, species.group <chr>, parvorder <chr>,
#   varietas <chr>
# ℹ Use `print(n = ...)` to see more rows
```

### Blast seeds

```{r}
seeds_output_path <- 'MiFish-U-local-20241011/get_seeds_local/MiFishU_filtered_get_seeds_local_output_with_taxonomy.csv' # this is output from get_seeds_local or get_seeds_remote


blast_seeds(seeds_output_path,
            blast_db_path,
            accession_taxa_sql_path,
            output_directory_path,
            metabarcode_name)    
```

```
Output directory: MiFish-U-local-20241011//blast_seeds_output

Blasting seeds.

BLAST round: 1
  56038 indices left to process.

genus has 5028 unique occurrences in the blast seeds data table.
These may be subset ...

tmp - Subsetting sample_indices

Running blastdbcmd on 1000 samples.

Calling blastn. This may take a long time.                                                                     
  1525877 blast hits returned.
  66192 unique blast hits after this round.

tmp - Subsetting sample_indices

Running blastdbcmd on 1000 samples.

Calling blastn. This may take a long time.                                                                     
  1830785 blast hits returned.
  124130 unique blast hits after this round.

tmp - Subsetting sample_indices

Running blastdbcmd on 1000 samples.

Calling blastn. This may take a long time.  
  1945508 blast hits returned.
  131260 unique blast hits after this round.

tmp - Subsetting sample_indices

Running blastdbcmd on 1000 samples.

Calling blastn. This may take a long time.
  1918665 blast hits returned.
  132480 unique blast hits after this round.

tmp - Subsetting sample_indices

Running blastdbcmd on 1000 samples.

Calling blastn. This may take a long time.                                                                     
  1894242 blast hits returned.
  134325 unique blast hits after this round.

tmp - length(sample_indices) <= max_to_blast

Running blastdbcmd on 28 samples.

Calling blastn. This may take a long time.                                                                     
  56378 blast hits returned.
  134345 unique blast hits after this round.

Previous unsampled indices exist, continuing from there.
BLAST round: 7
  1708 indices left to process.

genus has 0 unique occurrences in the blast seeds data table.
An additional 0 indices will be randomly sampled.

tmp - length(sample_indices) == length(unsampled_indices)

Running blastdbcmd on 1708 samples.

Calling blastn. This may take a long time.                                                                     
  478185 blast hits returned.
  360022 unique blast hits after this round.

Expanding multi taxids.

Blasting complete.

Wrangling results.

Done.
```

still running above... keep pasting output


### Dereplicate database

```{r}
summary_path <- "MiFish-U-local-20241011/blast_seeds_output/summary.csv" # path to the output from blast_seeds

derep_and_clean_db(output_directory_path, summary_path, metabarcode_name)
```

Checked `MiFIshU_derep_and_clean_taxonomy.txt'. At first glance, looks good. Lots of fish but also non-targetted mammals, some birds, insects, and even some bacteria.

### Make into blast formatted db

[Documentation](https://www.ncbi.nlm.nih.gov/books/NBK569841/)
(Run in terminal)



First remove excess text from fasta file
```{bash}
cd MiFish-U-local-20241011/derep_and_clean_db/
sed 's/_representative_of_[0-9]*_identical_accessions//g' MiFIshU_derep_and_clean.fasta > MiFishU_derep_and_clean_2.fasta

```
(Note different syntax for `sed` in [Mac OS vs other OS](https://www.cyberciti.biz/faq/how-to-use-sed-to-find-and-replace-text-in-files-in-linux-unix-shell/))


Get list of acc no's into new file
```{bash}
grep -e ">" MiFishU_derep_and_clean_2.fasta | awk 'sub(/^>/, "")' > AccNos.txt

```

Move into R
```{r}
accNos <-  read.table(file = "MiFish-U-local-20241011/derep_and_clean_db/AccNos.txt", header=FALSE,stringsAsFactors=FALSE)

accessions<-sapply(strsplit(accNos[,1],'\\|'),'[',1)
head(accessions)
```

Find taxonomy for accession numbers (takes a few minutes)
```{r}
taxaId<-accessionToTaxa(accessions,"taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql")
head(taxaId)
```


Concatenate with acc nos and export into txt file
```{r}
mapping_file <- data.frame(accessions, taxaId)
head(mapping_file)
```

```{r}
write.table(mapping_file, "MiFIsh-U-local-20241011/mapping_file.txt", sep='\t', col.names = FALSE, row.names = FALSE, quote=FALSE)
```




Use blast+ to make blastdb and call it nt (because this is how it's called in REVAMP pipeline. Want to try not to modify `REVAMP.sh` as much as possible)

```{bash}
cd ..
mkdir blastdb

makeblastdb -in derep_and_clean_db/MiFishU_derep_and_clean_2.fasta -dbtype nucl -parse_seqids -out blastdb/nt -blastdb_version 5 -taxid_map mapping_file.txt
```


And check that the database has taxIDs associated:
```{bash}
blastdbcmd -db blastdb/nt -entry all -outfmt "%T"
```
As long as this spits out numbers and not all zeroes, I think it worked.



## November 2024

Use rCRUX to generate V16S-U and VCOI-U libraries. We are trying to decide on next sequencing library and want to target reptilia, amphibia, mamamalia, aves. The paper suggests each set has different strengths but they are not broadly tested. We want to see which would be best for our local species.


### rCRUX - Build VCOI-U Database
We are considering new primer sets for targeting vertebrates. We found some good candidated from [Wang et al. 2023](https://www.frontiersin.org/journals/ecology-and-evolution/articles/10.3389/fevo.2023.1164206/full). Mr DNA thinks the 12S PCR would be difficult but he could get the 16S and COI to work well. In the paper, both have pretty good coverage for the mammals, reptiles, amphibians, birds. But they don't completely overlap- so use rCRUX to generate reference library seeds and see if the primers will hit our regional species that we might expect.


Local nt database was updated in October, don't need to re-install.

Check blast+ install and database download
```{bash}

cd /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt

conda activate REVAMPenv

blastdbcmd -db 'nt' -dbtype nucl -entry MN937193.1 -range 499-633
blastn -version


```
blastn: 2.10.1+
 Package: blast 2.10.1, build May 12 2020 13:06:02
 
** 11/20/24** NOTE- for some reason was getting a segmentation error. I re-unzipped all .gz files and that solved the problem.

VCOI-U
Amplicon size: 212
VCOI-U-F: 5'- CAYGCHTTTGTNATRATYTTYTT -3'
VCOI-U-R: 5'- GGRGGRTADACDGTYCANCCNGT -3'



```{r}
#dir.create("Wang-VCOI-U-local-20241121")

forward_primer_seq = "CAYGCHTTTGTNATRATYTTYTT"
reverse_primer_seq =  "GGRGGRTADACDGTYCANCCNGT"
output_directory_path <- "Wang-VCOI-U-local-20241121" # path to desired output directory
metabarcode_name <- "VCOI" # desired name of metabarcode locus
accession_taxa_sql_path <- "taxonomizr-acc-taxa-Oct2024/accessionTaxa.sql" # path to taxonomizr sql database
blast_db_path <- "/Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt"  # path to blast formatted database


get_seeds_local(forward_primer_seq,
                 reverse_primer_seq,
                 metabarcode_name,
                 output_directory_path,
                 accession_taxa_sql_path,
                 blast_db_path, mismatch = 0, max_to_blast = 2, num_fprimers_to_blast = 192, num_rprimers_to_blast = 1152)

```
Ran in Console instead of chunk bc of memory issues. Because I am using this for a different purpose (eg. not making ref library seeds but determining all possible seeds to look through hits), I changed the `num_fprimers_to_blast` and `num_rprimers_to_blast` to be the maximum number of combinations of primers based on degeneracy. Reduced `mismatch` to 0. 

This will take a long time. But increasing `max_to_blast` crashed my computer.

Terminal Output:
```
[1] "output directory exists"
Output directory: Wang-VCOI-U-local-20241121/get_seeds_local

No previous primer blast files found. Starting pipeline from beginning.

Examining primers for degenerate bases.
  192 forward primer(s) will be blasted.
  1152 reverse primer(s) will be blasted.

Reads will be blasted in subsets of up to 2 read(s). To change this, modify max_to_blast.                                       

Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query Wang-VCOI-U-local-20241121/get_seeds_local/VCOI_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1
Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query Wang-VCOI-U-local-20241121/get_seeds_local/VCOI_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1
Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query Wang-VCOI-U-local-20241121/get_seeds_local/VCOI_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1
Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query Wang-VCOI-U-local-20241121/get_seeds_local/VCOI_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1
Calling blastn for primers. This may take a long time.

blastn -db /Volumes/MyPassportforMac/eDNA-backup/databases/NCBI_blast_nt/nt -task blastn-short -query Wang-VCOI-U-local-20241121/get_seeds_local/VCOI_subset_for_blastn.fasta -outfmt "6 qseqid sgi saccver mismatch sstart send staxids" -evalue 3e+07 -num_alignments 10000000 -qcov_hsp_perc 90 -perc_identity 50 -reward 2 -word_size 7 -num_threads 1
```

~ Stopped. This would take weeks! Going in a different direction, with COI primers form Leray et al.~


## Jan 2025
### MIDORI
According to [Leray et al. 2022](https://onlinelibrary.wiley.com/doi/10.1002/edn3.303), MIDORI2 has higher diversity than BOLD and CO-ARBitrator and is regularly updated.

The [MIDORI2 site](https://www.reference-midori.info/) has multiple versions of the database, compatible with both BLAST+ and DADA2 (and others). The last GENBANK/ BLAST-compatible version was uploaded 2024-10-13, consistent with Genbank v263.

Some notes from the MIDORI README file:

- "sp" = those databases include sequences that lack binomial species-level description, such as "sp.," "aff.," "nr.," "cf.," "complex," and "nomen nudum." 
- "UNIQ" = UNIQ files contain all unique haplotypes associated with each species.
- "LONGEST" = LONGEST files contain the longest sequence for each species.
- List files are listing accession numbers collapsed into each sequence for uniq and longest files.

Based on this, I want to choose:
- "sp" files so that they include those references with no species name but with genus
- At first, I was considering using the "UNIQ" files incase there is some genetic variation among haplotypes, however I was getting errors when making the blastdb about duplicate accessions... so use `LONGEST` instead
- Try both the blast-formatted and the fasta version for now
- also download list files to help with mapping_file(?)
- We also provide "RAW" files, which contain complete taxonomy. Take a look

I first tried the blast-formatted db from MIDORI but REVAMP was having issues with the format of the db. I am getting an `mdb_env_open: No such file or directory` error, which according to [this](https://stackoverflow.com/questions/59476703/error-mdb-env-open-no-such-file-or-directory-blast-local-database-problem) is a corrupted file. It was similar for an older version of the db also. Plus the sequence names are not just a simplified accession number so this is going to be trouble down the road...

Try downloading the fasta version of the database, 'MIDORI2_UNIQ_NUC_SP_GB263_CO1_BLAST.fasta' and then, similar to above, use BLAST+ tools to turn it into a blast-formatted database

Downloaded FASTA-formatted version, `MIDORI2_UNIQ_NUC_SP_GB263_CO1_BLAST.fasta`


#### Import MIDORI db Fasta file

[Documentation](https://www.ncbi.nlm.nih.gov/books/NBK569841/)
(Run in terminal)

Use blast+ to make blastdb and call it nt (because this is how it's called in REVAMP pipeline. Want to try not to modify `REVAMP.sh` as much as possible)

```{bash}
cd /Volumes/MyPassportforMac/eDNA-backup/eDNA-databases/MIDORI2_NUC_GB263_CO1

unzip MIDORI2_LONGEST_NUC_GB263_CO1_BLAST.fasta.zip

mkdir blastdb
```


Count # of headers and sequences
```{bash}
grep "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST.fasta | wc -l
grep -v "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST.fasta | wc -l
```
226914 (Note- this is. ALOT let than the UNIQ file,  <10%)
3178246
Numbers should be the same but there are 3,178,246 sequences and only 226,914 headers
This probably because some sequences have a hard enter in the middle... Fix

Fix sequences so they are all on one line
```{bash}
awk '/^>/ {print (NR==1?"":"\n") $0; next} {printf "%s", $0} END {print ""}' MIDORI2_LONGEST_NUC_GB263_CO1_BLAST.fasta > MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta

```


Check number of headers and sequences again. Should be the same now
```{bash}
grep "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta | wc -l
grep -v "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta | wc -l
```
226914
226914
great!


Check for duplicate sequence names (this was a problem in the UNIQ file, may be ok here)-
```{bash}
awk '/^>/ {print $1}' MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta | sort | uniq -d
```
None, move on...

IF there were, remove duplicates while retaining first instance
```{bash}
<!-- awk ' -->
<!--   /^>/ {  -->
<!--     if ($1 in seen) {skip=1} else {seen[$1]=1; skip=0} -->
<!--   }  -->
<!--   !skip' MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta > MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta -->
```

Simplify headers to just accesion numbers
```{bash}
sed -E 's/^(>..[0-9]+\.[0-9]+).*/\1/' MIDORI2_LONGEST_NUC_GB263_CO1_BLAST2.fasta > MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta
```

Check for duplicates again now that headers have been simplified
```{bash}
awk '/^>/ {print $1}' MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta | sort | uniq -d
```
seems OK

Check for NAs in headers
```{bash}
grep "^>.*NA" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta
```
seems OK

Double check number of sequences remaining
```{bash}
grep "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta | wc -l
grep -v "^>" MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta | wc -l
```
  226914
  226914
  
  
Next I was trying to get taxonomy from taxonomizr but having A LOT of trouble. There are many things in this database which do not have taxonomy in taxonomizr, even things that were added to NCBI in 2021. So then the pipeline was only able to annotate 20-30% of sequences.
I don't know why this is but it seems to be a problem that is not unique to me ([Ex](https://github.com/benjjneb/dada2/issues/1520))
I had similar problem using the [premade rCRUX COI database](https://zenodo.org/records/8407603). Using this database the pipeline was only able to annotate 20-30% of ASVs. I even checked through the taxonomizr database very carefully and while it had some of the missing annotations, it was also missing a lot. Plut the taxonomizt db is 1,279,811 entries while the COI database is ~1.2 million and the MIDORI unique db is almost 3 million. I was to be stick with MIDORI to be as careful as possible.


Instead, switch to using taxonomy from MIDORI to make the mapping file...

#### Mapping file
The MIDORI2 db fasta file has headers like this: ``>MH535936.1.<1.>890###root_1;Eukaryota_2759;class_class_order_family_genus_Amoebozoa_sp._1892891;class_order_family_genus_Amoebozoa_sp._1892891;order_family_genus_Amoebozoa_sp._1892891;family_genus_Amoebozoa_sp._1892891;genus_Amoebozoa_sp._1892891;Amoebozoa_sp._1892891` 
Which includes taxIDs and taxonomy!


Extract the accession number and the taxID at the very end of the string. Use the first imported version of the fasta file:
```{r}
# library(stringr)

# Read the FASTA file
midori_fasta_headers <- readLines("MIDORI2_NUC_GB263_CO1/MIDORI2_LONGEST_NUC_GB263_CO1_BLAST.fasta")
midori_fasta_headers <- grep("^>", midori_fasta_headers, value = TRUE)

# Extract accession number and taxID
MIDORI_mapping_file <- data.frame(
  Accession_Number = sub("^>([A-Z]{1,2}\\d+\\.\\d+).*", "\\1", midori_fasta_headers),
  TaxID = sub(".*_(\\d+)$", "\\1", midori_fasta_headers)
)

# View result
MIDORI_mapping_file
```

Check for NAs and zeroes
```{r}
sum(is.na(MIDORI_mapping_file))
sum(MIDORI_mapping_file == 0)
```


If necessary, make sure taxaIDs are not in scientific notation
```{r}
#mapping_file$taxaId <- format(mapping_file$taxaId, scientific = FALSE)

```


export to mapping file as .txt and format into a blastdb
```{r}
write.table(MIDORI_mapping_file, "MIDORI2_NUC_GB263_CO1/mapping_file.txt", sep='\t', col.names = FALSE, row.names = FALSE, quote=FALSE)
```

#### Make blastdb
Make new blastdb using this mapping file and the blast3.fasta file (which should have only accessions in headers and simplified one-line sequences)
```{bash}
makeblastdb -in MIDORI2_LONGEST_NUC_GB263_CO1_BLAST3.fasta -dbtype nucl -parse_seqids -out blastdb/nt -blastdb_version 5 -taxid_map mapping_file.txt
```


No errors!...
Try blasting expeditiona-test against this... it works well and results are very similar to blasting against all of NCBI nt  
Check output of same dataset blasted against 
[NCBI nt](/Volumes/easystore/eDNA/shirp-edna/results-revamp-2024-CO1-expeditiona-test/NCBI_nt_0201_test_output/ASV2Taxonomy/KRONA_plots/results-revamp-2024-CO1-expeditiona-test_samplesSummedKRONA.html)
vs 
[MIDORI](/Volumes/easystore/eDNA/shirp-edna/results-revamp-2024-CO1-expeditiona-test/MIDORI_longest_0205_test_output/ASV2Taxonomy/KRONA_plots/results-revamp-2024-CO1-expeditiona-test_samplesSummedKRONA.html)

and actually it gives more taxonomic resolution for an important species (Mercenaria mercenaria), so use MIDORI.. Also blasting against local MIDORI is much much faster.

### Color scheme
```{r}
library(ggplot2) 
library(dplyr)
library(scales)        
library(RColorBrewer)
```

Generate a color key for plots so species colors are consistent across shirp

Import commonnames database (this is continually curated by me)
```{r}
commonames <- read.csv(file = "commonnames.csv")
```

Color by common names because there are some things that are tax IDed separately but are functionally the same (eg. Anchovies) and we group them together by calling them the same Common Name

```{r}
# Example: Create a list of elements corresponding to common names
elements <- unique(commonames$CommonName)

# Generate a diverging color palette
num_colors <- length(elements)
palette <- colorRampPalette(brewer.pal(11, "Paired"))(num_colors)  

# Shuffle colors randomly
set.seed(123)  # For reproducibility
palette <- sample(palette)

# Assign colors to each element
color_assignment <- setNames(palette, elements)

# View first few assignments
head(color_assignment)


# Convert to a data frame for ggplot
df <- data.frame(CommonName = names(color_assignment), Color = color_assignment)

# Plot colors as a tile plot
ggplot(df, aes(x = CommonName, y = 1, fill = Color)) +
  geom_tile() +
  scale_fill_identity() +  # Use the assigned colors directly
  theme_minimal() +
  theme(axis.text.x = element_blank(),  
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank()) +
  labs(title = "Random Diverging Colors for Common Names")
```

Convert element back into data frame and export for use in other scripts
```{r}
commonnames_colors <- left_join(commonames, df, by = c("CommonName" = "CommonName")) 
commonnames_colors
```

Overwrite commonnames file with colors column-
```{r}
write.csv(commonnames_colors,file = "commonnames.csv", row.names = FALSE)
```

